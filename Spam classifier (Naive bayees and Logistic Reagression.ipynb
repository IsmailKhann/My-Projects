{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"C:\\\\Users\\\\Shawaf Khan\\\\Desktop\\\\spam.csv\",encoding=\"ISO-8859-1\")\n",
    "data[\"v1\"].replace(to_replace=[\"ham\",\"spam\"],value=[0,1],inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    new=[char for char in text if char not in string.punctuation]\n",
    "    new=''.join(new)\n",
    "    clean=[ch for ch in new.split() if ch not in stopwords.words('english') ]\n",
    "    return clean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, I, dont, think, goes, usf, lives, around...\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##To check weather the function is working\n",
    "data[\"v2\"].head().apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "skt=CountVectorizer(analyzer=process).fit_transform(data[\"v2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating training data and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(skt,data[\"v1\"],test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 11495)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(x_train))\n",
    "print(y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:                  precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3631\n",
      "           1       0.98      0.98      0.98       504\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       0.99      0.99      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "Confusion Matrix:   \n",
      " [[3623    8]\n",
      " [  10  494]]\n",
      "Acurracy:   0.9956469165659009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "predict=classifier.predict(x_train)\n",
    "print(\"Classification Report:   \",classification_report(y_train,predict))\n",
    "print(\"Confusion Matrix:   \\n\",confusion_matrix(y_train,predict))\n",
    "print(\"Acurracy:  \",accuracy_score(y_train,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:                  precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       885\n",
      "           1       0.84      0.91      0.88       149\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.91      0.94      0.93      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n",
      "Confusion Matrix:  \n",
      "  [[860  25]\n",
      " [ 13 136]]\n",
      "Acurracy:   0.9632495164410058\n"
     ]
    }
   ],
   "source": [
    "### REport for test data\n",
    "predict_test=classifier.predict(x_test)\n",
    "print(\"Classification Report:   \",classification_report(y_test,predict_test))\n",
    "print(\"Confusion Matrix:  \\n \",confusion_matrix(y_test,predict_test))\n",
    "print(\"Acurracy:  \",accuracy_score(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value:    [0 0 0 ... 0 0 0]\n",
      "Actual values:    [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted value:   \",classifier.predict(x_test))\n",
    "print(\"Actual values:   \",y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating spam classifier using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_test1,y_train1,y_test=train_test_split(skt,data[\"v1\"],test_size=0.30,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifierr=LogisticRegression(solver='liblinear',penalty='l2')\n",
    "classifierr.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972360420121614\n"
     ]
    }
   ],
   "source": [
    "pred=classifierr.predict(x_train1)\n",
    "\n",
    "print(accuracy_score(y_train1,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
